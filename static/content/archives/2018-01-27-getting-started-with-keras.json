{
  "categories": [
    "Python"
  ],
  "date": "2018-01-27T11:01:04.000Z",
  "draft": false,
  "slug": "getting-started-with-keras",
  "title": "Python の深層学習ライブラリ Keras で手書き文字の認識を始めよう",
  "bodyContent": "![](/images/2018/01/keras.png)\n\n去年の始めに読んだ[ゼロから作る Deep Learning](/archives/deep-learning-from-scratch/) では、外部ライブラリを極力使用せずにディープラーニング（深層学習）の基礎を学べる良書だった。この記事では、ニューラルネットの構造を簡単に記述できる [Keras](https://github.com/keras-team/keras) ライブラリを使用し、手書き文字の認識まで一通り行う。\n\n## 開発環境\n\n- Anaconda 1.6.5 / [Anaconda - python.jp](https://www.python.jp/install/windows/anaconda/install_anaconda.html)\n- Python 3.6.3 :: Anaconda, Inc.\n- Keras `$ pip install tensorflow`, `$ pip install keras`\n- Jupyter Notebook の起動 `$ jupyter notebook`\n\n## 画像を読み込む\n\nまずは、手書き文字を datasets から取得します。\n\n```python\nfrom keras.datasets import mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train.shape, y_train.shape, x_test.shape, y_test.shape\n# 学習用データ、学習用正解データ、テスト用データ、テスト用正解データ\n# ((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))\n```\n\n`x_train` には、`(28, 28)` の行列の白黒の画像データ（数値は 0~255）が 60,000 枚用意されています。`y_train` には、例えば `y_train[0] = 5` などの正解の数値が格納されています。`(28, 28)` の行列の 0~255 の数値を元に、「この配置の並びは数字の 5 だ」というように、コンピュータに学習させるのが目的になります。\n\n次はニューラルネットで扱えるようにデータの加工をしていきます。\n\n```python\nfrom keras.utils import to_categorical\n\nx_train = x_train.reshape(-1, 784) / 255\nx_test = x_test.reshape(-1, 784) /255\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape\n# ((60000, 784), (60000, 10), (10000, 784), (10000, 10))\n```\n\n`x_train` の行列を `(28, 28) -> (784,)` に変更し、255 でブロードキャスト割り算をして、0.0 ~ 1.0 の範囲内にまとめます（この後の計算用の関数に通すため）。ここでは、1 次元に置き換えているため、画像の持つ 2 次元データがロストしています。それを上手く活かすには畳み込み層（Convolution）が使われますが、ここでは割愛します。\n\n`y_train` は `y_train[0]` を見ると `array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])` のようになっています。これは数字の 5（0 から数え始めて 6 番目）が答えとなっていることを示しています。\n\n## ニューラルネットワークの構築と学習\n\nそれでは、実際のニューラルネットワークの構築に入ります。\n\n```python\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\n\nmodel = Sequential() # モデルを作成\nmodel.add(Dense(units=256, input_shape=(784,))) # 784 -> 256 に線形変換\nmodel.add(Activation('relu')) # ReLU 関数で活性化\nmodel.add(Dense(units=100))\nmodel.add(Activation('relu'))\nmodel.add(Dense(units=10)) # 最終的に 0 ~ 9 にする\nmodel.add(Activation('softmax'))\nmodel.summary()\n# _________________________________________________________________\n# Layer (type)                 Output Shape              Param #   \n# =================================================================\n# dense_1 (Dense)              (None, 256)               200960    \n# _________________________________________________________________\n# activation_1 (Activation)    (None, 256)               0         \n# _________________________________________________________________\n# dense_2 (Dense)              (None, 100)               25700     \n# _________________________________________________________________\n# activation_2 (Activation)    (None, 100)               0         \n# _________________________________________________________________\n# dense_3 (Dense)              (None, 10)                1010      \n# _________________________________________________________________\n# activation_3 (Activation)    (None, 10)                0         \n# =================================================================\n# Total params: 227,670\n# Trainable params: 227,670\n# Non-trainable params: 0\n# _________________________________________________________________\n```\n\n誤差関数 `loss='categorical_crossentropy'`, 最適化手法 `optimizer='sgd'`, 評価関数 `metrics=['accuracy']` でモデルをコンパイルします。そして、一度に学習させる枚数 `batch_size=100`, 学習のエポック数 `epochs=10` で学習を開始します。\n\n```python\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer='sgd',\n    metrics=['accuracy']\n)\n\nmodel.fit(\n  x_train, y_train,\n  batch_size=100, epochs=10,\n  validation_data=(x_test, y_test)\n)\n\n# Train on 60000 samples, validate on 10000 samples\n# Epoch 1/10 loss: 0.1978 - acc: 0.9441 - val_loss: 0.1907 - val_acc: 0.9445\n# Epoch 2/10 loss: 0.1888 - acc: 0.9466 - val_loss: 0.1847 - val_acc: 0.9459\n# Epoch 3/10 loss: 0.1800 - acc: 0.9492 - val_loss: 0.1757 - val_acc: 0.9486\n# Epoch 4/10 loss: 0.1724 - acc: 0.9515 - val_loss: 0.1695 - val_acc: 0.9498\n# Epoch 5/10 loss: 0.1653 - acc: 0.9534 - val_loss: 0.1638 - val_acc: 0.9514\n# Epoch 6/10 loss: 0.1588 - acc: 0.9553 - val_loss: 0.1584 - val_acc: 0.9522\n# Epoch 7/10 loss: 0.1527 - acc: 0.9569 - val_loss: 0.1530 - val_acc: 0.9538\n# Epoch 8/10 loss: 0.1471 - acc: 0.9587 - val_loss: 0.1508 - val_acc: 0.9561\n# Epoch 9/10 loss: 0.1418 - acc: 0.9603 - val_loss: 0.1439 - val_acc: 0.9572\n# Epoch 10/10 loss: 0.1366 - acc: 0.9617 - val_loss: 0.1411 - val_acc: 0.9578\n```\n\n学習用データでは、正答率 `acc: 0.9617`, テスト用データでは、正答率 `val_acc: 0.9578` となりました。どちらも 96% の確率で与えられたデータから正しい数値を答えられることを示しています。\n\n{{<amazon id=\"4873117585\" title=\"ゼロから作るDeep Learning ―Pythonで学ぶディープラーニングの理論と実装\" src=\"https://images-na.ssl-images-amazon.com/images/I/512ru2i5gyL._SL160_.jpg\">}}",
  "bodyHtml": "<p><img src=\"/images/2018/01/keras.png\" alt=\"\"></p>\n<p>去年の始めに読んだ<a href=\"/archives/deep-learning-from-scratch/\">ゼロから作る Deep Learning</a> では、外部ライブラリを極力使用せずにディープラーニング（深層学習）の基礎を学べる良書だった。この記事では、ニューラルネットの構造を簡単に記述できる <a href=\"https://github.com/keras-team/keras\">Keras</a> ライブラリを使用し、手書き文字の認識まで一通り行う。</p>\n<h2>開発環境</h2>\n<ul>\n<li>Anaconda 1.6.5 / <a href=\"https://www.python.jp/install/windows/anaconda/install_anaconda.html\">Anaconda - python.jp</a></li>\n<li>Python 3.6.3 :: Anaconda, Inc.</li>\n<li>Keras <code>$ pip install tensorflow</code>, <code>$ pip install keras</code></li>\n<li>Jupyter Notebook の起動 <code>$ jupyter notebook</code></li>\n</ul>\n<h2>画像を読み込む</h2>\n<p>まずは、手書き文字を datasets から取得します。</p>\n<pre><code class=\"hljs\"><span class=\"hljs-keyword\">from</span> keras.datasets <span class=\"hljs-keyword\">import</span> mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train.shape, y_train.shape, x_test.shape, y_test.shape\n<span class=\"hljs-comment\"># 学習用データ、学習用正解データ、テスト用データ、テスト用正解データ</span>\n<span class=\"hljs-comment\"># ((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))</span></code></pre><p><code>x_train</code> には、<code>(28, 28)</code> の行列の白黒の画像データ（数値は 0~255）が 60,000 枚用意されています。<code>y_train</code> には、例えば <code>y_train[0] = 5</code> などの正解の数値が格納されています。<code>(28, 28)</code> の行列の 0~255 の数値を元に、「この配置の並びは数字の 5 だ」というように、コンピュータに学習させるのが目的になります。</p>\n<p>次はニューラルネットで扱えるようにデータの加工をしていきます。</p>\n<pre><code class=\"hljs\"><span class=\"hljs-keyword\">from</span> keras.utils <span class=\"hljs-keyword\">import</span> to_categorical\n\nx_train = x_train.reshape(<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">784</span>) / <span class=\"hljs-number\">255</span>\nx_test = x_test.reshape(<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">784</span>) /<span class=\"hljs-number\">255</span>\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape\n<span class=\"hljs-comment\"># ((60000, 784), (60000, 10), (10000, 784), (10000, 10))</span></code></pre><p><code>x_train</code> の行列を <code>(28, 28) -&gt; (784,)</code> に変更し、255 でブロードキャスト割り算をして、0.0 ~ 1.0 の範囲内にまとめます（この後の計算用の関数に通すため）。ここでは、1 次元に置き換えているため、画像の持つ 2 次元データがロストしています。それを上手く活かすには畳み込み層（Convolution）が使われますが、ここでは割愛します。</p>\n<p><code>y_train</code> は <code>y_train[0]</code> を見ると <code>array([ 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])</code> のようになっています。これは数字の 5（0 から数え始めて 6 番目）が答えとなっていることを示しています。</p>\n<h2>ニューラルネットワークの構築と学習</h2>\n<p>それでは、実際のニューラルネットワークの構築に入ります。</p>\n<pre><code class=\"hljs\"><span class=\"hljs-keyword\">from</span> keras.models <span class=\"hljs-keyword\">import</span> Sequential\n<span class=\"hljs-keyword\">from</span> keras.layers <span class=\"hljs-keyword\">import</span> Dense, Activation\n\nmodel = Sequential() <span class=\"hljs-comment\"># モデルを作成</span>\nmodel.add(Dense(units=<span class=\"hljs-number\">256</span>, input_shape=(<span class=\"hljs-number\">784</span>,))) <span class=\"hljs-comment\"># 784 -&gt; 256 に線形変換</span>\nmodel.add(Activation(<span class=\"hljs-string\">'relu'</span>)) <span class=\"hljs-comment\"># ReLU 関数で活性化</span>\nmodel.add(Dense(units=<span class=\"hljs-number\">100</span>))\nmodel.add(Activation(<span class=\"hljs-string\">'relu'</span>))\nmodel.add(Dense(units=<span class=\"hljs-number\">10</span>)) <span class=\"hljs-comment\"># 最終的に 0 ~ 9 にする</span>\nmodel.add(Activation(<span class=\"hljs-string\">'softmax'</span>))\nmodel.summary()\n<span class=\"hljs-comment\"># _________________________________________________________________</span>\n<span class=\"hljs-comment\"># Layer (type)                 Output Shape              Param #   </span>\n<span class=\"hljs-comment\"># =================================================================</span>\n<span class=\"hljs-comment\"># dense_1 (Dense)              (None, 256)               200960    </span>\n<span class=\"hljs-comment\"># _________________________________________________________________</span>\n<span class=\"hljs-comment\"># activation_1 (Activation)    (None, 256)               0         </span>\n<span class=\"hljs-comment\"># _________________________________________________________________</span>\n<span class=\"hljs-comment\"># dense_2 (Dense)              (None, 100)               25700     </span>\n<span class=\"hljs-comment\"># _________________________________________________________________</span>\n<span class=\"hljs-comment\"># activation_2 (Activation)    (None, 100)               0         </span>\n<span class=\"hljs-comment\"># _________________________________________________________________</span>\n<span class=\"hljs-comment\"># dense_3 (Dense)              (None, 10)                1010      </span>\n<span class=\"hljs-comment\"># _________________________________________________________________</span>\n<span class=\"hljs-comment\"># activation_3 (Activation)    (None, 10)                0         </span>\n<span class=\"hljs-comment\"># =================================================================</span>\n<span class=\"hljs-comment\"># Total params: 227,670</span>\n<span class=\"hljs-comment\"># Trainable params: 227,670</span>\n<span class=\"hljs-comment\"># Non-trainable params: 0</span>\n<span class=\"hljs-comment\"># _________________________________________________________________</span></code></pre><p>誤差関数 <code>loss='categorical_crossentropy'</code>, 最適化手法 <code>optimizer='sgd'</code>, 評価関数 <code>metrics=['accuracy']</code> でモデルをコンパイルします。そして、一度に学習させる枚数 <code>batch_size=100</code>, 学習のエポック数 <code>epochs=10</code> で学習を開始します。</p>\n<pre><code class=\"hljs\">model.compile(\n    loss=<span class=\"hljs-string\">'categorical_crossentropy'</span>,\n    optimizer=<span class=\"hljs-string\">'sgd'</span>,\n    metrics=[<span class=\"hljs-string\">'accuracy'</span>]\n)\n\nmodel.fit(\n  x_train, y_train,\n  batch_size=<span class=\"hljs-number\">100</span>, epochs=<span class=\"hljs-number\">10</span>,\n  validation_data=(x_test, y_test)\n)\n\n<span class=\"hljs-comment\"># Train on 60000 samples, validate on 10000 samples</span>\n<span class=\"hljs-comment\"># Epoch 1/10 loss: 0.1978 - acc: 0.9441 - val_loss: 0.1907 - val_acc: 0.9445</span>\n<span class=\"hljs-comment\"># Epoch 2/10 loss: 0.1888 - acc: 0.9466 - val_loss: 0.1847 - val_acc: 0.9459</span>\n<span class=\"hljs-comment\"># Epoch 3/10 loss: 0.1800 - acc: 0.9492 - val_loss: 0.1757 - val_acc: 0.9486</span>\n<span class=\"hljs-comment\"># Epoch 4/10 loss: 0.1724 - acc: 0.9515 - val_loss: 0.1695 - val_acc: 0.9498</span>\n<span class=\"hljs-comment\"># Epoch 5/10 loss: 0.1653 - acc: 0.9534 - val_loss: 0.1638 - val_acc: 0.9514</span>\n<span class=\"hljs-comment\"># Epoch 6/10 loss: 0.1588 - acc: 0.9553 - val_loss: 0.1584 - val_acc: 0.9522</span>\n<span class=\"hljs-comment\"># Epoch 7/10 loss: 0.1527 - acc: 0.9569 - val_loss: 0.1530 - val_acc: 0.9538</span>\n<span class=\"hljs-comment\"># Epoch 8/10 loss: 0.1471 - acc: 0.9587 - val_loss: 0.1508 - val_acc: 0.9561</span>\n<span class=\"hljs-comment\"># Epoch 9/10 loss: 0.1418 - acc: 0.9603 - val_loss: 0.1439 - val_acc: 0.9572</span>\n<span class=\"hljs-comment\"># Epoch 10/10 loss: 0.1366 - acc: 0.9617 - val_loss: 0.1411 - val_acc: 0.9578</span></code></pre><p>学習用データでは、正答率 <code>acc: 0.9617</code>, テスト用データでは、正答率 <code>val_acc: 0.9578</code> となりました。どちらも 96% の確率で与えられたデータから正しい数値を答えられることを示しています。</p>\n<p>{{&lt;amazon id=&quot;4873117585&quot; title=&quot;ゼロから作るDeep Learning ―Pythonで学ぶディープラーニングの理論と実装&quot; src=&quot;https://images-na.ssl-images-amazon.com/images/I/512ru2i5gyL.<em>SL160</em>.jpg&quot;&gt;}}</p>\n",
  "dir": "static/content/archives",
  "base": "2018-01-27-getting-started-with-keras.json",
  "ext": ".json",
  "sourceBase": "2018-01-27-getting-started-with-keras.md",
  "sourceExt": ".md"
}